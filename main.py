import streamlit as st
from PIL import Image
import io
import os
import base64
import requests
import json
import openai
from dotenv import load_dotenv

# --- èª­ã¿è¾¼ã¿ ---
load_dotenv()
GOOGLE_API_KEY = st.secrets["GOOGLE_CLOUD_VISION_API_KEY"]
DEEPL_API_KEY = st.secrets["DEEPL_API_KEY"]
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
openai.api_key = OPENAI_API_KEY

# --- OCRé–¢æ•° ---
def ocr_google_vision(image):
    buffered = io.BytesIO()
    image.save(buffered, format="JPEG")
    img_base64 = base64.b64encode(buffered.getvalue()).decode()

    url = f"https://vision.googleapis.com/v1/images:annotate?key={GOOGLE_API_KEY}"
    body = {
        "requests": [
            {
                "image": {"content": img_base64},
                "features": [{"type": "TEXT_DETECTION"}],
                "imageContext": {"languageHints": ["ja"]}
            }
        ]
    }

    response = requests.post(url, headers={"Content-Type": "application/json"}, data=json.dumps(body))
    if response.status_code == 200:
        annotations = response.json()["responses"][0].get("textAnnotations")
        if annotations:
            return annotations[0]["description"]
        else:
            return ""
    else:
        return f"[Error] {response.status_code}: {response.text}"

# --- DeepLç¿»è¨³ ---
def translate_deepl(text):
    url = "https://api-free.deepl.com/v2/translate"
    data = {
        "auth_key": DEEPL_API_KEY,
        "text": text,
        "source_lang": "JA",
        "target_lang": "EN"
    }
    response = requests.post(url, data=data)
    return response.json()["translations"][0]["text"] if response.status_code == 200 else "ç¿»è¨³ã‚¨ãƒ©ãƒ¼"

# --- ChatGPTã§æ–™ç†èª¬æ˜å–å¾— ---
def get_dish_analysis(dish_name):
    prompt = f"""æ–™ç†åï¼šã€Œ{dish_name}ã€\n1. ä¸€èˆ¬çš„ã«ä½¿ã‚ã‚Œã‚‹ææ–™ï¼ˆç°¡æ½”ã«ï¼‰\n2. ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ã®å¯èƒ½æ€§ã®ã‚ã‚‹é£Ÿæ\n3. ç°¡å˜ãªèª¬æ˜ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰\n4. æ­´å²ã‚„å°è©±ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰"""
    try:
        res = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        return res.choices[0].message.content
    except Exception as e:
        return f"Error: {e}"

# --- UIæ§‹æˆ ---
st.set_page_config(layout="wide", page_title="Menu Translator")
st.title("ğŸ½ï¸ é«˜ç´šæ„Ÿã®ã‚ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç¿»è¨³ã‚¢ãƒ—ãƒª")
st.markdown("ç”»åƒã‹ã‚‰æ—¥æœ¬èªãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è‹±èªã«ç¿»è¨³ã—ã€ã•ã‚‰ã«æ–™ç†ã®è§£èª¬ã‚‚è¡¨ç¤ºã—ã¾ã™ã€‚")

uploaded_file = st.file_uploader("ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png"])
if uploaded_file:
    image = Image.open(uploaded_file)
    st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)

    text = ocr_google_vision(image)
    lines = [line.strip() for line in text.splitlines() if line.strip()]

    if lines:
        st.markdown("---")
        st.subheader("ç¿»è¨³ã¨è§£èª¬çµæœ")
        for line in lines:
            translated = translate_deepl(line)
            with st.expander(f"ğŸ´ {line} â¡ï¸ {translated}"):
                st.markdown(f"**ğŸ” è©³ç´°è§£æï¼š**")
                st.markdown(get_dish_analysis(line))
    else:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆãŒèª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ç”»åƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

           